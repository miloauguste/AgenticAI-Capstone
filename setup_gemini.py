#!/usr/bin/env python3
"""
Setup script for Google Gemini LLM integration
Helps configure the system to use Google Gemini as the primary LLM
"""

import os
import sys

def setup_gemini_configuration():
    """Guide user through Gemini setup"""
    
    print("ğŸš€ Google Gemini LLM Setup")
    print("=" * 50)
    
    # Check if API key is already set
    current_key = os.getenv('GOOGLE_API_KEY')
    if current_key:
        print(f"âœ… Google API Key is already configured")
        print(f"   Key starts with: {current_key[:10]}...")
        
        response = input("\nDo you want to update it? (y/n): ").lower()
        if response != 'y':
            print("âœ… Using existing Google API Key")
            return test_gemini_connection()
    
    print("\nğŸ“‹ To use Google Gemini, you need a Google API Key:")
    print("   1. Go to https://aistudio.google.com/")
    print("   2. Sign in with your Google account")
    print("   3. Click 'Get API key' in the left sidebar")
    print("   4. Click 'Create API key' -> 'Create API key in new project'")
    print("   5. Copy the generated API key")
    
    print("\nğŸ”‘ Enter your Google API Key:")
    api_key = input("GOOGLE_API_KEY: ").strip()
    
    if not api_key:
        print("âŒ No API key provided. Setup cancelled.")
        return False
    
    # Validate API key format (basic check)
    if not api_key.startswith('AIza') or len(api_key) < 30:
        print("âš ï¸ Warning: API key format doesn't look correct.")
        print("   Google API keys usually start with 'AIza' and are ~39 characters long")
        
        response = input("Continue anyway? (y/n): ").lower()
        if response != 'y':
            print("Setup cancelled.")
            return False
    
    # Set environment variable
    os.environ['GOOGLE_API_KEY'] = api_key
    
    # Create .env file for persistence
    try:
        with open('.env', 'w') as f:
            f.write(f"GOOGLE_API_KEY={api_key}\n")
            f.write("# Google Gemini API Key for LLM backend\n")
            f.write("# This enables full CrewAI agent functionality\n")
        
        print("âœ… API key saved to .env file")
        print("ğŸ’¡ The .env file will be loaded automatically by the system")
        
    except Exception as e:
        print(f"âš ï¸ Warning: Could not save .env file: {str(e)}")
        print("ğŸ’¡ You can manually set the environment variable:")
        print(f"   export GOOGLE_API_KEY={api_key}")
    
    return test_gemini_connection()

def test_gemini_connection():
    """Test if Gemini is working correctly"""
    
    print("\nğŸ§ª Testing Google Gemini connection...")
    
    try:
        # Import the system and test LLM configuration
        sys.path.append(os.getcwd())
        from multi_agent_system import FeedbackAnalysisSystem
        
        print("   Initializing system...")
        system = FeedbackAnalysisSystem()
        
        # Check if Gemini backend is configured
        llm_backend = system._get_llm_backend()
        
        if llm_backend and 'gemini' in str(type(llm_backend)).lower():
            print("âœ… Google Gemini LLM backend successfully configured!")
            print(f"   Backend type: {type(llm_backend).__name__}")
            
            # Try a simple test (optional)
            try:
                print("   Testing basic functionality...")
                # Test with a simple prompt
                result = llm_backend.invoke("Say 'Hello from Gemini!'")
                if result and hasattr(result, 'content'):
                    print(f"   ğŸ‰ Gemini response: {result.content[:50]}...")
                    print("âœ… Google Gemini is working perfectly!")
                    return True
                else:
                    print("âœ… Google Gemini is configured (response test inconclusive)")
                    return True
                    
            except Exception as e:
                print(f"âš ï¸ Gemini configured but test failed: {str(e)}")
                print("ğŸ’¡ This might be due to API quotas or network issues")
                return True
                
        elif llm_backend:
            print(f"â„¹ï¸ Different LLM backend configured: {type(llm_backend).__name__}")
            print("ğŸ’¡ Gemini was not selected (other LLM has priority)")
            return True
            
        else:
            print("âŒ No LLM backend configured")
            print("ğŸ’¡ Check your API key and try again")
            return False
            
    except Exception as e:
        print(f"âŒ Test failed: {str(e)}")
        print("ğŸ’¡ Make sure the multi_agent_system.py file is present and working")
        return False

def show_usage_instructions():
    """Show how to use the system with Gemini"""
    
    print("\nğŸ“– Usage Instructions")
    print("=" * 50)
    
    print("ğŸ¯ Now you can use Google Gemini with the system:")
    print("")
    print("1. **UI Mode (Recommended):**")
    print("   python -m streamlit run ui_app.py")
    print("   â†’ Select 'Generate Tickets' from navigation")
    print("   â†’ Choose 'Full CrewAI (Needs LLM)' processing mode")
    print("   â†’ All agents will use Google Gemini for reasoning")
    print("")
    print("2. **Command Line Mode:**")
    print("   python test_simple.py")
    print("   â†’ Tests individual agents with mock data")
    print("   â†’ Shows colorful logging output")
    print("")
    print("3. **Hybrid Mode (Fallback):**")
    print("   â†’ If Gemini has issues, system falls back to hybrid mode")
    print("   â†’ All agents still work with colorful logging")
    print("   â†’ No LLM required for basic functionality")
    print("")
    print("ğŸ¨ Features with Gemini:")
    print("   â€¢ Intelligent feedback classification")  
    print("   â€¢ Advanced bug analysis and prioritization")
    print("   â€¢ Smart feature extraction and assessment")
    print("   â€¢ Context-aware ticket generation")
    print("   â€¢ Quality review with detailed scoring")

def main():
    """Main setup function"""
    
    print("Google Gemini LLM Setup for Intelligent Feedback Analysis System")
    print("=" * 80)
    
    # Run setup
    success = setup_gemini_configuration()
    
    if success:
        show_usage_instructions()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ Setup Complete!")
        print("   Google Gemini is now configured as your LLM backend")
        print("   Run: python -m streamlit run ui_app.py")
        print("=" * 50)
        
    else:
        print("\n" + "=" * 50) 
        print("âŒ Setup Failed")
        print("   Please check your API key and try again")
        print("   You can still use the system in Hybrid mode")
        print("=" * 50)

if __name__ == "__main__":
    main()